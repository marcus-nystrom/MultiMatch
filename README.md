Matlab code for using a MultiDimensional scanpath comparison method--'MultiMatch'. Go into the toolbox directory and type "help doComparison" it will tell you about the function which uses the MultiMatch analysis code. If you pass in two sets of fixation data it will output the 5 dimension similarity scores. E.g. "S = doComparison(fix1,fix2)" where fix1 and fix2 are rows of x,y,duration coordinates for fixations. Also note: you will need to install the bioinformatics toolbox.

If you use MultiMatch in published work, please cite the relevant papers:
  * Jarodzka, H.; Holmqvist, K. & Nyström, M. A vector-based, multidimensional scanpath similarity measure Proceedings of the 2010 Symposium on Eye-Tracking Research & Applications, 2010, 211-218
  * Dewhurst, R.; Nyström, M.; Jarodzka, H.; Foulsham, T.; Johansson, R. & Holmqvist, K. It depends on how you look at it: Scanpath comparison in multiple dimensions with MultiMatch, a vector-based approach Behavior Research Methods, Springer, 2012, 1-22
  * Foulsham, T., Dewhurst, R., Nyström, M., Jarodzka, H., Johansson, R., Underwood, G. & Holmqvist, K. (2012). Comparing scanpaths during scene encoding and recognition: A multi-dimensional approach. Journal of Eye Movement Research, 5, 1-14.

DUE TO MANY REQUESTS, THIS CODE HAS BEEN MADE PUBLICLY AVAILABLE ON GITHUB. IT IS DELIVERED 'AS IS' AS A SERVICE TO THE COMMUNITY. WE DO NOT SUPPORT IT.


**Data disclaimer, limitations and conditions of release**

By downloading this data set, you expressly agree to the following conditions of release and acknowledge the following disclaimers issued by the authors:

A. Conditions of Release
Data are available by permission of the authors. Use of data in publications, either digital or hardcopy, must cite at least one of the above mentioned papers.

B. Disclaimer of Liability
The authors shall not be held liable for any improper or incorrect use or application of the data provided, and assume no responsibility for the use or application of the data or interpretations based on the data, or information derived from interpretation of the data. In no event shall the authors be liable for any direct, indirect or incidental damage, injury, loss, harm, illness or other damage or injury arising from the use or application of these data. This disclaimer of liability applies to any direct, indirect, incidental, exemplary, special or consequential damages or injury, even if advised of the possibility of such damage or injury, including but not limited to those caused by any failure of performance, error, omission, defect, delay in operation or transmission, computer virus, alteration, use, application, analysis or interpretation of data.

C. Disclaimer of Accuracy of Data
No warranty, expressed or implied, is made regarding the accuracy, adequacy, completeness, reliability or usefulness of any data provided. These data are provided "as is." All warranties of any kind, expressed or implied, including but not limited to fitness for a particular use, freedom from computer viruses, the quality, accuracy or completeness of data or information, and that the use of such data or information will not infringe any patent, intellectual property or proprietary rights of any party, are disclaimed. The user expressly acknowledges that the data may contain some nonconformities, defects, or errors. The authors do not warrant that the data will meet the user’s needs or expectations, or that all nonconformities, defects, or errors can or will be corrected. The authors are not inviting reliance on these data, and the user should always verify actual data.